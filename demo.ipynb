{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#混淆矩阵\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [0, 0,0,1]\n",
    "y_pred = [0, 1,0,0]\n",
    "c = confusion_matrix(y_true, y_pred)\n",
    "print(c)\n",
    "conf_matrix = torch.zeros(2,2)\n",
    "\n",
    "y_true = torch.tensor([[0, 0,0,1]])\n",
    "y_pred = torch.tensor([[0, 1,0,0]])\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计数\n",
    "from numpy import array\n",
    "\n",
    "def conunt(array,x):\n",
    "    index = array==x\n",
    "    return index.sum()\n",
    "\n",
    "a = array([0,1,0])\n",
    "c = conunt(a,1)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524288\n"
     ]
    }
   ],
   "source": [
    "#矩阵计数\n",
    "import torch\n",
    "import numpy as np\n",
    "def conunt(array,x):\n",
    "    index = array==x\n",
    "    return index.sum()\n",
    "x = torch.randn(2, 2, 512, 512)\n",
    "N, _, h, w = x.shape\n",
    "pred = x.permute(0, 2, 3, 1).reshape(-1, 2).argmax(axis=1).reshape(N, h, w)\n",
    "pred2 = x.argmax(dim=1)\n",
    "pred = pred.numpy()\n",
    "pred2 = pred2.numpy()\n",
    "a  = pred==pred2\n",
    "print(conunt(a,1))\n",
    "# a = conunt(pred==pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 :  1378530930\n",
      "class 1 :  27216270\n",
      "frenquent 0 :  0.9806392856411167\n",
      "frenquent 1 :  0.019360714358883303\n",
      "weight 0 :  0.5098714760067081\n",
      "weight 1 :  25.825493353791686\n"
     ]
    }
   ],
   "source": [
    "#计算数据集的正反例权重\n",
    "import os,cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class_0 = 0\n",
    "class_1 = 0\n",
    "file_path = r'D:\\software\\Code\\code-file\\image\\mydata\\my_data2\\anno\\train'\n",
    "for p in os.listdir(file_path):\n",
    "    image_p = os.path.join(file_path,p)\n",
    "    image = cv2.imread(image_p,flags=cv2.IMREAD_GRAYSCALE)\n",
    "    class_0 += (np.sum(image==0))\n",
    "    class_1 += (np.sum(image==1))\n",
    "frenquent_0 = class_0/(class_0+class_1)\n",
    "frenquent_1 = class_1/(class_0+class_1)\n",
    "weight_0 = (1/2)/frenquent_0\n",
    "weight_1 = (1/2)/frenquent_1\n",
    "print(\"class 0 : \",class_0)\n",
    "print(\"class 1 : \",class_1)\n",
    "print(\"frenquent 0 : \",frenquent_0)\n",
    "print(\"frenquent 1 : \",frenquent_1)\n",
    "print(\"weight 0 : \",weight_0)\n",
    "print(\"weight 1 : \",weight_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#测试输出\n",
    "import torch,numpy\n",
    "import model \n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "image_P= r\"D:\\software\\Code\\code-file\\image\\mydata\\test_data\\imgs\\train\\label100_rand_74.jpg\"\n",
    "net = model.setr()\n",
    "checkpoint = torch.load(r\"D:\\software\\Code\\code-file\\pytorch-model\\saved\\models\\setr\\0804_160928\\checkpoint-epoch30.pth\",map_location='cpu')\n",
    "state_dict = checkpoint['state_dict']\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net.load_state_dict(state_dict)\n",
    "net = net.to(device)\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    image = Image.open(image_P)\n",
    "    to_tensor = transforms.ToTensor()\n",
    "    image = to_tensor(image).unsqueeze(dim=0).to(device)\n",
    "    output = net(image)\n",
    "    pred = torch.squeeze(torch.argmax(output, dim=1))\n",
    "    img = pred.numpy()\n",
    "    num = numpy.sum(img==1)\n",
    "    print(num)\n",
    "    img = numpy.where(img==1,255,0)\n",
    "    img = Image.fromarray(numpy.uint8(img))\n",
    "    img.save(r\"D:\\31890\\Desktop\\1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('D:\\software\\Code\\code-file\\pytorch-model')\n",
    "from model_arc.backbone.fcn import *\n",
    "from model_arc.decoder_head.decoder import *\n",
    "from model_arc.backbone.VIT import *\n",
    "from base import BaseModel\n",
    "class setr(BaseModel):\n",
    "    def __init__(self, \n",
    "                        image_size=512,\n",
    "                        patch_size=16, \n",
    "                        num_classes = 2, \n",
    "                        dim = 1024, \n",
    "                        depth = 6, \n",
    "                        heads = 16, \n",
    "                        hid_dim = 4096,\n",
    "                        pretrain = False):\n",
    "        super().__init__()\n",
    "        self.pretrain = pretrain\n",
    "        self.h = int(image_size/patch_size)\n",
    "        self.w = int(image_size/patch_size)\n",
    "        self.dim = dim\n",
    "        self.encoder = ViT(\n",
    "                image_size =image_size,\n",
    "                patch_size = patch_size,\n",
    "                dim=dim,\n",
    "                depth= depth,\n",
    "                heads=heads,\n",
    "                hid_dim=hid_dim,\n",
    "                dropout = 0.1,\n",
    "                emb_dropout = 0.1)\n",
    "        self.decoder = SETR_up(\n",
    "            in_channels=dim,\n",
    "            out_channels=num_classes\n",
    "        )\n",
    "        self.neck = nn.Linear(dim,dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.neck(x)\n",
    "        x = rearrange(x, \"b (h w) c -> b c h w\", h = self.h , w = self.w , c = self.dim)\n",
    "        out = self.decoder(x)\n",
    "        return out\n",
    "net = setr()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SETR_up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, features=[512, 256, 128, 64]):\n",
    "        super().__init__()\n",
    "        self.decoder_1 = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, features[0], 3, padding=1),\n",
    "                    nn.BatchNorm2d(features[0]),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "                )\n",
    "        self.decoder_2 = nn.Sequential(\n",
    "                    nn.Conv2d(features[0], features[1], 3, padding=1),\n",
    "                    nn.BatchNorm2d(features[1]),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "                )\n",
    "        self.decoder_3 = nn.Sequential(\n",
    "            nn.Conv2d(features[1], features[2], 3, padding=1),\n",
    "            nn.BatchNorm2d(features[2]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        )\n",
    "        self.decoder_4 = nn.Sequential(\n",
    "            nn.Conv2d(features[2], features[3], 3, padding=1),\n",
    "            nn.BatchNorm2d(features[3]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        )\n",
    "\n",
    "        self.final_out = nn.Conv2d(features[-1], out_channels, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = self.decoder_1(x)\n",
    "        print(x.shape)\n",
    "        x = self.decoder_2(x)\n",
    "        print(x.shape)\n",
    "        x = self.decoder_3(x)\n",
    "        print(x.shape)\n",
    "        x = self.decoder_4(x)\n",
    "        print(x.shape)\n",
    "        x = self.final_out(x)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "decoder = SETR_up(1024,2)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    " \n",
    "class BasicBlock(nn.Module):\n",
    "    expansion: int = 4\n",
    "    def __init__(self, inplanes, planes, stride = 1, downsample = None, groups = 1,\n",
    "        base_width = 64, dilation = 1, norm_layer = None):\n",
    "        \n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes ,kernel_size=3, stride=stride, \n",
    "                               padding=dilation,groups=groups, bias=False,dilation=dilation)\n",
    "        \n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes ,kernel_size=3, stride=stride, \n",
    "                               padding=dilation,groups=groups, bias=False,dilation=dilation)\n",
    "        \n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    " \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    " \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    " \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    " \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    " \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    " \n",
    "        return out\n",
    " \n",
    " \n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    " \n",
    "    def __init__(self, inplanes, planes, stride=1, downsample= None,\n",
    "        groups = 1, base_width = 64, dilation = 1, norm_layer = None,):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.0)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride, bias=False, padding=dilation, dilation=dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = nn.Conv2d(width, planes * self.expansion, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    " \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    " \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    " \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    " \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    " \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    " \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    " \n",
    " \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,block, layers,num_classes = 1000, zero_init_residual = False, groups = 1,\n",
    "        width_per_group = 64, replace_stride_with_dilation = None, norm_layer = None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "            \n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\n",
    "                \"replace_stride_with_dilation should be None \"\n",
    "                f\"or a 3-element tuple, got {replace_stride_with_dilation}\"\n",
    "            )\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    " \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    " \n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
    " \n",
    "    def _make_layer(\n",
    "        self,\n",
    "        block,\n",
    "        planes,\n",
    "        blocks,\n",
    "        stride = 1,\n",
    "        dilate = False,\n",
    "    ):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = stride\n",
    "            \n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes,  planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                norm_layer(planes * block.expansion))\n",
    " \n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer\n",
    "            )\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    self.inplanes,\n",
    "                    planes,\n",
    "                    groups=self.groups,\n",
    "                    base_width=self.base_width,\n",
    "                    dilation=self.dilation,\n",
    "                    norm_layer=norm_layer,\n",
    "                )\n",
    "            )\n",
    "        return nn.Sequential(*layers)\n",
    " \n",
    "    def _forward_impl(self, x):\n",
    "        out = []\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        out.append(x)\n",
    "        x = self.layer2(x)\n",
    "        out.append(x)\n",
    "        x = self.layer3(x)\n",
    "        out.append(x)\n",
    "        x = self.layer4(x)\n",
    "        out.append(x)\n",
    "        return out\n",
    " \n",
    "    def forward(self, x) :\n",
    "        return self._forward_impl(x)\n",
    "    def _resnet(block, layers, pretrained_path = None, **kwargs,):\n",
    "        model = ResNet(block, layers, **kwargs)\n",
    "        if pretrained_path is not None:\n",
    "            model.load_state_dict(torch.load(pretrained_path),  strict=False)\n",
    "        return model\n",
    "    \n",
    "    def resnet50(pretrained_path=None, **kwargs):\n",
    "        return ResNet._resnet(Bottleneck, [3, 4, 6, 3],pretrained_path,**kwargs)\n",
    "    \n",
    "    def resnet101(pretrained_path=None, **kwargs):\n",
    "        return ResNet._resnet(Bottleneck, [3, 4, 23, 3],pretrained_path,**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PPM(nn.ModuleList):\n",
    "    def __init__(self, pool_sizes, in_channels, out_channels):\n",
    "        super(PPM, self).__init__()\n",
    "        self.pool_sizes = pool_sizes\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        for pool_size in pool_sizes:\n",
    "            self.append(\n",
    "                nn.Sequential(\n",
    "                    nn.AdaptiveMaxPool2d(pool_size),\n",
    "                    nn.Conv2d(self.in_channels, self.out_channels, kernel_size=1),\n",
    "                )\n",
    "            )     \n",
    "            \n",
    "    def forward(self, x):\n",
    "        out_puts = []\n",
    "        for ppm in self:\n",
    "            ppm_out = nn.functional.interpolate(ppm(x), size=(x.size(2), x.size(3)), mode='bilinear', align_corners=True)\n",
    "            out_puts.append(ppm_out)\n",
    "        return out_puts\n",
    " \n",
    "    \n",
    "class PPMHEAD(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, pool_sizes = [1, 2, 3, 6],num_classes=31):\n",
    "        super(PPMHEAD, self).__init__()\n",
    "        self.pool_sizes = pool_sizes\n",
    "        self.num_classes = num_classes\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.psp_modules = PPM(self.pool_sizes, self.in_channels, self.out_channels)\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels + len(self.pool_sizes)*self.out_channels, 4*self.out_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(4*self.out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.psp_modules(x)\n",
    "        out.append(x)\n",
    "        out = torch.cat(out, 1)\n",
    "        out = self.final(out)\n",
    "        return out\n",
    " \n",
    "class FPNHEAD(nn.Module):\n",
    "    def __init__(self, channels=2048):\n",
    "        super(FPNHEAD, self).__init__()\n",
    "        self.PPMHead = PPMHEAD(in_channels=2048, out_channels=512)\n",
    "        \n",
    "        self.Conv_fuse1 = nn.Sequential(\n",
    "            nn.Conv2d(channels//2, channels//2, 1),\n",
    "            nn.BatchNorm2d(channels//2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.Conv_fuse1_ = nn.Sequential(\n",
    "            nn.Conv2d(channels//2 + channels, channels//2, 1),\n",
    "            nn.BatchNorm2d(channels//2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.Conv_fuse2 = nn.Sequential(\n",
    "            nn.Conv2d(channels//4, channels//4, 1),\n",
    "            nn.BatchNorm2d(channels//4),\n",
    "            nn.ReLU()\n",
    "        )    \n",
    "        self.Conv_fuse2_ = nn.Sequential(\n",
    "            nn.Conv2d(channels//2 + channels//4, channels//4, 1),\n",
    "            nn.BatchNorm2d(channels//4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.Conv_fuse3 = nn.Sequential(\n",
    "            nn.Conv2d(channels//8, channels//8, 1),\n",
    "            nn.BatchNorm2d(channels//8),\n",
    "            nn.ReLU()\n",
    "        ) \n",
    "        self.Conv_fuse3_ = nn.Sequential(\n",
    "            nn.Conv2d(channels//4 + channels//8, channels//8, 1),\n",
    "            nn.BatchNorm2d(channels//8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "        self.fuse_all = nn.Sequential(\n",
    "            nn.Conv2d(channels*2 - channels//8, channels//4, 1),\n",
    "            nn.BatchNorm2d(channels//4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_fpn):\n",
    "        x1 = self.PPMHead(input_fpn[-1])\n",
    "        \n",
    "        x = nn.functional.interpolate(x1, size=(x1.size(2)*2, x1.size(3)*2),mode='bilinear', align_corners=True)\n",
    "        x = torch.cat([x, self.Conv_fuse1(input_fpn[-2])], dim = 1)\n",
    "        x2 = self.Conv_fuse1_(x)\n",
    "        \n",
    "        x = nn.functional.interpolate(x2, size=(x2.size(2)*2, x2.size(3)*2),mode='bilinear', align_corners=True)\n",
    "        x = torch.cat([x, self.Conv_fuse2(input_fpn[-3])], dim = 1)\n",
    "        x3 = self.Conv_fuse2_(x)  \n",
    "        \n",
    "        x = nn.functional.interpolate(x3, size=(x3.size(2)*2, x3.size(3)*2),mode='bilinear', align_corners=True)\n",
    "        x = torch.cat([x, self.Conv_fuse3(input_fpn[-4])], dim = 1)\n",
    "        x4 = self.Conv_fuse3_(x)\n",
    " \n",
    "        x1 = F.interpolate(x1, x4.size()[-2:],mode='bilinear', align_corners=True)\n",
    "        x2 = F.interpolate(x2, x4.size()[-2:],mode='bilinear', align_corners=True)\n",
    "        x3 = F.interpolate(x3, x4.size()[-2:],mode='bilinear', align_corners=True)\n",
    " \n",
    "        x = self.fuse_all(torch.cat([x1, x2, x3, x4], 1))\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class UPerNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(UPerNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.backbone = ResNet.resnet50(replace_stride_with_dilation=[1,2,4])\n",
    "        self.in_channels = 2048\n",
    "        self.channels = 512\n",
    "        self.decoder = FPNHEAD()\n",
    "        self.cls_seg = nn.Sequential(\n",
    "            nn.Conv2d(512, self.num_classes, kernel_size=3, padding=1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x) \n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        x = nn.functional.interpolate(x, size=(x.size(2)*4, x.size(3)*4),mode='bilinear', align_corners=True)\n",
    "        x = self.cls_seg(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "x = torch.rand(1,3,512,512)\n",
    "x1 = torch.rand(1,256,128,128)\n",
    "x2 = torch.rand(1,512,64,64)\n",
    "x3 = torch.rand(1,1024,32,32)\n",
    "x4 = torch.rand(1,2048,16,16)\n",
    "x_ = [x1,x2,x3,x4]\n",
    "\n",
    "\n",
    "# net = UPerNet(3)\n",
    "head = FPNHEAD()\n",
    "print(head(x_).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, epsilon: float = 0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, preds, target):\n",
    "        n = preds.size()[-1]\n",
    "        log_preds = F.log_softmax(preds, dim=-1)\n",
    "        loss = self.reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        \n",
    "        return self.linear_combination(loss / n, nll, self.epsilon)\n",
    "\n",
    "    def linear_combination(x, y, epsilon):\n",
    "        return epsilon * x + (1 - epsilon) * y\n",
    "\n",
    "\n",
    "    def reduce_loss(loss, reduction='mean'):\n",
    "        return loss.mean() if reduction == 'mean' else loss.sum() if reduction == 'sum' else loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b72bce0f774da0affb1409740e09e5f72c8a559958be0d948f9a4e26f76c5539"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
